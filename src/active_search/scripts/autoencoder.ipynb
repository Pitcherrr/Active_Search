{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%source` not found.\n"
     ]
    }
   ],
   "source": [
    "%source /opt/ros/noetic/setup.bash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import rospkg\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import open3d as o3d\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from tqdm import trange\n",
    "\n",
    "LATENT_CODE_SIZE = 128\n",
    "amcm = 24\n",
    "\n",
    "class Lambda(nn.Module):\n",
    "    def __init__(self, function):\n",
    "        super(Lambda, self).__init__()\n",
    "        self.function = function\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.function(x)\n",
    "\n",
    "def load_voxel_grids(file_paths):\n",
    "    voxel_grids = []\n",
    "    voxel_size = 0.0075\n",
    "    grid_size = (40, 40, 40)\n",
    "    num_files = len(file_paths)\n",
    "    assert num_files % 2 == 0, \"The number of file paths should be even.\"\n",
    "\n",
    "    for i in range(0, num_files, 2):\n",
    "\n",
    "        # Grid 1 is the TSDF as a point cloud \n",
    "        grid1 = np.zeros(grid_size)\n",
    "        pcd1 = o3d.io.read_point_cloud(file_paths[i])\n",
    "        points1 = np.asarray(pcd1.points)\n",
    "        distances = np.asarray(pcd1.colors)[:, [0]]\n",
    "\n",
    "        grid1 = np.zeros((40, 40, 40), dtype=np.float32)\n",
    "        indices = (points1 // voxel_size).astype(int)\n",
    "        grid1[tuple(indices.T)] = distances.squeeze()\n",
    "        # grid1[points1[:, 0], points1[:, 1], points1[:, 2]] = 1\n",
    "        grid1 = grid1[np.newaxis, :, :, :]\n",
    "        \n",
    "        # Grid 2 is the occluded voxel locations\n",
    "        grid2 = np.zeros(grid_size)\n",
    "        pcd2 = o3d.io.read_point_cloud(file_paths[i + 1])\n",
    "        points2 = np.asarray(pcd2.points).astype(int)\n",
    "        grid2[points2[:, 0], points2[:, 1], points2[:, 2]] = 1\n",
    "        grid2 = grid2[np.newaxis, :, :, :]\n",
    "\n",
    "        # Concatenate the two voxel grids along the channel dimension (dim=0)\n",
    "        combined_grid = np.concatenate((grid1, grid2), axis=0)\n",
    "        voxel_grids.append(combined_grid)\n",
    "\n",
    "    return voxel_grids\n",
    "\n",
    "def split_combined_voxel_grids(combined_grids):\n",
    "    voxel_grids = []\n",
    "    for combined_grid in combined_grids:\n",
    "        # Remove the channel dimension (dim=0) to get the individual voxel grids\n",
    "        grid1 = combined_grid[0, :, :, :]\n",
    "        grid2 = combined_grid[1, :, :, :]\n",
    "\n",
    "        voxel_grids.append(grid1)\n",
    "        voxel_grids.append(grid2)\n",
    "\n",
    "    return voxel_grids\n",
    "\n",
    "# Step 2: Autoencoder Architecture (define the neural network)\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Autoencoder, self).__init__()\n",
    "\n",
    "        # Encoder layers\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv3d(2, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool3d(kernel_size=2, stride=2),\n",
    "            nn.Conv3d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool3d(kernel_size=2, stride=2),\n",
    "            nn.Conv3d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),  # Flatten the 3D tensor into a 1D vector\n",
    "            nn.Linear(128 * 10 * 10 * 10, 1000)  # Map to the desired latent dimension of 1000\n",
    "        )\n",
    "\n",
    "        # # Decoder layers\n",
    "        # self.decoder = nn.Sequential(\n",
    "        #     nn.Conv3d(128, 64, kernel_size=3, stride=1, padding=1),\n",
    "        #     nn.ReLU(),\n",
    "        #     nn.Upsample(scale_factor=2),\n",
    "        #     nn.Conv3d(64, 32, kernel_size=3, stride=1, padding=1),\n",
    "        #     nn.ReLU(),\n",
    "        #     nn.Upsample(scale_factor=2),\n",
    "        #     nn.Conv3d(32, 2, kernel_size=3, stride=1, padding=1),\n",
    "        #     nn.Sigmoid()\n",
    "        # )\n",
    "                # Decoder layers\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(1000, 128 * 10 * 10 * 10),  # Map from the latent space back to the decoder input shape\n",
    "            nn.Unflatten(1, (128, 10, 10, 10)),  # Reshape the tensor back to 4D (batch_size, channels, height, width, depth)\n",
    "            nn.ReLU(),\n",
    "            nn.Conv3d(128, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            nn.Conv3d(64, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            nn.Conv3d(32, 2, kernel_size=3, stride=1, padding=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "        # # Encoder layers\n",
    "        # self.encoder = nn.Sequential(\n",
    "        #     nn.Conv3d(2, 32, kernel_size=3, stride=1, padding=1),\n",
    "        #     nn.BatchNorm3d(32),\n",
    "        #     nn.LeakyReLU(negative_slope=0.2, inplace=True),\n",
    "\n",
    "        #     nn.Conv3d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "        #     nn.BatchNorm3d(64),\n",
    "        #     nn.LeakyReLU(negative_slope=0.2, inplace=True),\n",
    "\n",
    "        #     nn.Conv3d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "        #     nn.BatchNorm3d(128),\n",
    "        #     nn.LeakyReLU(negative_slope=0.2, inplace=True),\n",
    "\n",
    "        #     nn.Flatten(),  # Flatten the 3D tensor into a 1D vector\n",
    "        #     nn.Linear(128*10*10*10, 1000)  # Map to the desired latent dimension of 1000\n",
    "        # )\n",
    "\n",
    "        # # Decoder layers\n",
    "        # self.decoder = nn.Sequential(\n",
    "        #     nn.Linear(1000, 128 * 10 * 10 * 10),  # Map from the latent space back to the decoder input shape\n",
    "        #     nn.BatchNorm1d(128 * 10 * 10 * 10),\n",
    "        #     nn.LeakyReLU(negative_slope=0.2, inplace=True),\n",
    "        #     nn.Unflatten(1, (128, 10, 10, 10)),  # Reshape the tensor back to 4D (batch_size, channels, height, width, depth)\n",
    "            \n",
    "        #     nn.ConvTranspose3d(128, 64, kernel_size = 4, stride = 1),\n",
    "        #     nn.BatchNorm3d(64),\n",
    "        #     nn.LeakyReLU(negative_slope=0.2, inplace=True),\n",
    "\n",
    "        #     nn.ConvTranspose3d(64, 32, kernel_size = 4, stride = 2, padding = 1),\n",
    "        #     nn.BatchNorm3d(32),\n",
    "        #     nn.LeakyReLU(negative_slope=0.2, inplace=True),\n",
    "\n",
    "        #     nn.ConvTranspose3d(32, 2, kernel_size = 4, stride = 2, padding = 1)\n",
    "        # )\n",
    "\n",
    "        # self.encoder = nn.Sequential(\n",
    "        #     nn.Conv3d(in_channels = 2, out_channels = 1 * amcm, kernel_size = 4, stride = 2, padding = 1),\n",
    "        #     nn.BatchNorm3d(1 * amcm),\n",
    "        #     nn.LeakyReLU(negative_slope=0.2, inplace=True),\n",
    "            \n",
    "        #     nn.Conv3d(in_channels = 1 * amcm, out_channels = 2 * amcm, kernel_size = 4, stride = 2, padding = 1),\n",
    "        #     nn.BatchNorm3d(2 * amcm),\n",
    "        #     nn.LeakyReLU(negative_slope=0.2, inplace=True),\n",
    "            \n",
    "        #     nn.Conv3d(in_channels = 2 * amcm, out_channels = 4 * amcm, kernel_size = 4, stride = 2, padding = 1),\n",
    "        #     nn.BatchNorm3d(4 * amcm),\n",
    "        #     nn.LeakyReLU(negative_slope=0.2, inplace=True),\n",
    "            \n",
    "        #     nn.Conv3d(in_channels = 4 * amcm, out_channels = LATENT_CODE_SIZE * 2, kernel_size = 4, stride = 1),\n",
    "        #     nn.BatchNorm3d(LATENT_CODE_SIZE * 2),\n",
    "        #     nn.LeakyReLU(negative_slope=0.2, inplace=True),\n",
    "            \n",
    "        #     nn.Flatten(),\n",
    "        #     # Lambda(lambda x: x.reshape(x.shape[0], -1)),\n",
    "        #     nn.Linear(in_features = LATENT_CODE_SIZE * 2, out_features=LATENT_CODE_SIZE)\n",
    "        # )\n",
    "        \n",
    "        \n",
    "        # self.decoder = nn.Sequential(            \n",
    "        #     # nn.Linear(in_features = LATENT_CODE_SIZE, out_features=LATENT_CODE_SIZE * 2),\n",
    "        #     # nn.BatchNorm1d(LATENT_CODE_SIZE * 2),\n",
    "        #     # nn.LeakyReLU(negative_slope=0.2, inplace=True),\n",
    "\n",
    "        #     nn.Linear(1000, 128 * 10 * 10 * 10),  # Map from the latent space back to the decoder input shape\n",
    "        #     nn.Unflatten(1, (128, 10, 10, 10)),  # Reshape the tensor back to 4D (batch_size, channels, height, width, depth)\n",
    "            \n",
    "        #     # Lambda(lambda x: x.reshape(-1, LATENT_CODE_SIZE * 2, 1, 1, 1)),\n",
    "        #     nn.ReLU(),\n",
    "        #     nn.ConvTranspose3d(in_channels = LATENT_CODE_SIZE * 2, out_channels = 4 * amcm, kernel_size = 4, stride = 1),\n",
    "        #     nn.BatchNorm3d(4 * amcm),\n",
    "        #     nn.LeakyReLU(negative_slope=0.2, inplace=True),\n",
    "\n",
    "        #     nn.ConvTranspose3d(in_channels = 4 * amcm, out_channels = 2 * amcm, kernel_size = 4, stride = 2, padding = 1),\n",
    "        #     nn.BatchNorm3d(2 * amcm),\n",
    "        #     nn.LeakyReLU(negative_slope=0.2, inplace=True),\n",
    "\n",
    "        #     nn.ConvTranspose3d(in_channels = 2 * amcm, out_channels = 1 * amcm, kernel_size = 4, stride = 2, padding = 1),\n",
    "        #     nn.BatchNorm3d(1 * amcm),\n",
    "        #     nn.LeakyReLU(negative_slope=0.2, inplace=True),\n",
    "\n",
    "        #     nn.ConvTranspose3d(in_channels = 1 * amcm, out_channels = 2, kernel_size = 4, stride = 2, padding = 1)\n",
    "        # )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x = torch.cat((x1, x2), dim=1)\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n",
    "\n",
    "# Step 3: Training\n",
    "# Training function\n",
    "def train_autoencoder(train_data, val_data, num_epochs, batch_size):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(\"Training on:\", device)\n",
    "    autoencoder = Autoencoder().to(device)\n",
    "    # use binary cross entropy\n",
    "    # criterion = nn.MSELoss()\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = optim.Adam(autoencoder.parameters(), lr=0.001)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = torch.utils.data.DataLoader(val_data, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    train_losses = [] \n",
    "    val_losses = []    \n",
    "\n",
    "    t = trange(num_epochs)\n",
    "    for epoch in t:\n",
    "        running_loss = 0.0\n",
    "        for batch in train_loader:  # Loop through batches in DataLoader\n",
    "            inputs = batch.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = autoencoder(inputs)\n",
    "            loss = criterion(outputs, inputs)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "        epoch_loss = running_loss / len(train_loader.dataset)\n",
    "        train_losses.append(epoch_loss)\n",
    "\n",
    "        # Validation\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:  # Loop through batches in DataLoader\n",
    "                inputs = batch.to(device)\n",
    "                outputs = autoencoder(inputs)\n",
    "                loss = criterion(outputs, inputs)\n",
    "                val_loss += loss.item() * inputs.size(0)\n",
    "            val_loss /= len(val_loader.dataset)\n",
    "            val_losses.append(val_loss)\n",
    "\n",
    "        t.set_description(f'Epoch {epoch + 1}/{num_epochs}, Train Loss: {epoch_loss:.4f}, Val Loss: {val_loss:.4f}')\n",
    "    \n",
    "    plot_autoencoder(train_losses, val_losses)\n",
    "\n",
    "    return autoencoder\n",
    "\n",
    "def plot_autoencoder(train, val):\n",
    "    epochs = range(1, len(train) + 1)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(epochs, train, label='Train Loss')\n",
    "    plt.plot(epochs, val, label='Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "def encode_voxel_grids(autoencoder, new_voxel_grids):\n",
    "    # new_voxel_grids = torch.tensor(new_voxel_grids.reshape(-1, 40*40*40), dtype=torch.float32)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    new_voxel_grids = new_voxel_grids.clone().detach().to(device)\n",
    "    encoded_voxel = autoencoder.encoder(new_voxel_grids)\n",
    "    return encoded_voxel\n",
    "\n",
    "def decode_voxel_grids(autoencoder, encoded_voxel):\n",
    "    decoded_voxel = autoencoder.decoder(encoded_voxel)\n",
    "    return decoded_voxel\n",
    "\n",
    "# Function to get file paths for all .pcd files in the specified directory\n",
    "def get_pcd_file_paths(directory_path):\n",
    "    file_paths = []\n",
    "    for filename in os.listdir(directory_path):\n",
    "        if filename.endswith(\".pcd\"):\n",
    "            file_path = os.path.join(directory_path, filename)\n",
    "            file_paths.append(file_path)\n",
    "    # Sort the file paths numerically based on the numeric part of the filename\n",
    "    file_paths.sort(key=lambda x: (int(re.search(r'\\d+', x).group()), \"occ\" in x, x))\n",
    "    return file_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 490.00 MiB (GPU 0; 7.78 GiB total capacity; 5.32 GiB already allocated; 441.62 MiB free; 6.02 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 25\u001b[0m\n\u001b[1;32m     22\u001b[0m batch_size \u001b[39m=\u001b[39m \u001b[39m32\u001b[39m\n\u001b[1;32m     24\u001b[0m \u001b[39m# Train the autoencoder\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m trained_autoencoder \u001b[39m=\u001b[39m train_autoencoder(train_data, val_data, num_epochs, batch_size)\n",
      "Cell \u001b[0;32mIn[1], line 231\u001b[0m, in \u001b[0;36mtrain_autoencoder\u001b[0;34m(train_data, val_data, num_epochs, batch_size)\u001b[0m\n\u001b[1;32m    229\u001b[0m     loss \u001b[39m=\u001b[39m criterion(outputs, inputs)\n\u001b[1;32m    230\u001b[0m     loss\u001b[39m.\u001b[39mbackward()\n\u001b[0;32m--> 231\u001b[0m     optimizer\u001b[39m.\u001b[39;49mstep()\n\u001b[1;32m    232\u001b[0m     running_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mitem() \u001b[39m*\u001b[39m inputs\u001b[39m.\u001b[39msize(\u001b[39m0\u001b[39m)\n\u001b[1;32m    233\u001b[0m epoch_loss \u001b[39m=\u001b[39m running_loss \u001b[39m/\u001b[39m \u001b[39mlen\u001b[39m(train_loader\u001b[39m.\u001b[39mdataset)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/optim/optimizer.py:280\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    277\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m}\u001b[39;00m\u001b[39m must return None or a tuple of (new_args, new_kwargs),\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    278\u001b[0m                                \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbut got \u001b[39m\u001b[39m{\u001b[39;00mresult\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 280\u001b[0m out \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    281\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    283\u001b[0m \u001b[39m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/optim/optimizer.py:33\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     32\u001b[0m     torch\u001b[39m.\u001b[39mset_grad_enabled(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdefaults[\u001b[39m'\u001b[39m\u001b[39mdifferentiable\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m---> 33\u001b[0m     ret \u001b[39m=\u001b[39m func(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     34\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     35\u001b[0m     torch\u001b[39m.\u001b[39mset_grad_enabled(prev_grad)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/optim/adam.py:141\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    130\u001b[0m     beta1, beta2 \u001b[39m=\u001b[39m group[\u001b[39m'\u001b[39m\u001b[39mbetas\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m    132\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_init_group(\n\u001b[1;32m    133\u001b[0m         group,\n\u001b[1;32m    134\u001b[0m         params_with_grad,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    138\u001b[0m         max_exp_avg_sqs,\n\u001b[1;32m    139\u001b[0m         state_steps)\n\u001b[0;32m--> 141\u001b[0m     adam(\n\u001b[1;32m    142\u001b[0m         params_with_grad,\n\u001b[1;32m    143\u001b[0m         grads,\n\u001b[1;32m    144\u001b[0m         exp_avgs,\n\u001b[1;32m    145\u001b[0m         exp_avg_sqs,\n\u001b[1;32m    146\u001b[0m         max_exp_avg_sqs,\n\u001b[1;32m    147\u001b[0m         state_steps,\n\u001b[1;32m    148\u001b[0m         amsgrad\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mamsgrad\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    149\u001b[0m         beta1\u001b[39m=\u001b[39;49mbeta1,\n\u001b[1;32m    150\u001b[0m         beta2\u001b[39m=\u001b[39;49mbeta2,\n\u001b[1;32m    151\u001b[0m         lr\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mlr\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    152\u001b[0m         weight_decay\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mweight_decay\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    153\u001b[0m         eps\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39meps\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    154\u001b[0m         maximize\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mmaximize\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    155\u001b[0m         foreach\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mforeach\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    156\u001b[0m         capturable\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mcapturable\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    157\u001b[0m         differentiable\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mdifferentiable\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    158\u001b[0m         fused\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mfused\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    159\u001b[0m         grad_scale\u001b[39m=\u001b[39;49m\u001b[39mgetattr\u001b[39;49m(\u001b[39mself\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mgrad_scale\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m    160\u001b[0m         found_inf\u001b[39m=\u001b[39;49m\u001b[39mgetattr\u001b[39;49m(\u001b[39mself\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mfound_inf\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m    161\u001b[0m     )\n\u001b[1;32m    163\u001b[0m \u001b[39mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/optim/adam.py:281\u001b[0m, in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    279\u001b[0m     func \u001b[39m=\u001b[39m _single_tensor_adam\n\u001b[0;32m--> 281\u001b[0m func(params,\n\u001b[1;32m    282\u001b[0m      grads,\n\u001b[1;32m    283\u001b[0m      exp_avgs,\n\u001b[1;32m    284\u001b[0m      exp_avg_sqs,\n\u001b[1;32m    285\u001b[0m      max_exp_avg_sqs,\n\u001b[1;32m    286\u001b[0m      state_steps,\n\u001b[1;32m    287\u001b[0m      amsgrad\u001b[39m=\u001b[39;49mamsgrad,\n\u001b[1;32m    288\u001b[0m      beta1\u001b[39m=\u001b[39;49mbeta1,\n\u001b[1;32m    289\u001b[0m      beta2\u001b[39m=\u001b[39;49mbeta2,\n\u001b[1;32m    290\u001b[0m      lr\u001b[39m=\u001b[39;49mlr,\n\u001b[1;32m    291\u001b[0m      weight_decay\u001b[39m=\u001b[39;49mweight_decay,\n\u001b[1;32m    292\u001b[0m      eps\u001b[39m=\u001b[39;49meps,\n\u001b[1;32m    293\u001b[0m      maximize\u001b[39m=\u001b[39;49mmaximize,\n\u001b[1;32m    294\u001b[0m      capturable\u001b[39m=\u001b[39;49mcapturable,\n\u001b[1;32m    295\u001b[0m      differentiable\u001b[39m=\u001b[39;49mdifferentiable,\n\u001b[1;32m    296\u001b[0m      grad_scale\u001b[39m=\u001b[39;49mgrad_scale,\n\u001b[1;32m    297\u001b[0m      found_inf\u001b[39m=\u001b[39;49mfound_inf)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/optim/adam.py:507\u001b[0m, in \u001b[0;36m_multi_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[1;32m    505\u001b[0m     exp_avg_sq_sqrt \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39m_foreach_sqrt(device_exp_avg_sqs)\n\u001b[1;32m    506\u001b[0m     torch\u001b[39m.\u001b[39m_foreach_div_(exp_avg_sq_sqrt, bias_correction2_sqrt)\n\u001b[0;32m--> 507\u001b[0m     denom \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49m_foreach_add(exp_avg_sq_sqrt, eps)\n\u001b[1;32m    509\u001b[0m torch\u001b[39m.\u001b[39m_foreach_addcdiv_(params_, device_exp_avgs, denom, step_size)\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 490.00 MiB (GPU 0; 7.78 GiB total capacity; 5.32 GiB already allocated; 441.62 MiB free; 6.02 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "rospack = rospkg.RosPack()\n",
    "# pkg_root = Path(rospack.get_path(\"active_search\"))\n",
    "data_folder_path = \"/home/pitcher/dev_ws/thesis_ws/active_search/src/active_search/training/\"\n",
    "file_paths = get_pcd_file_paths(data_folder_path)  # List of file paths to your .pcd files\n",
    "voxel_grids = load_voxel_grids(file_paths)\n",
    "\n",
    "# Convert to PyTorch tensors and flatten the voxel grids\n",
    "# voxel_tensors = torch.tensor(np.asarray(voxel_grids).reshape(-1, 40*40*40), dtype=torch.float32)\n",
    "voxel_tensors = torch.tensor(np.asarray(voxel_grids), dtype=torch.float32)\n",
    "\n",
    "num_data = int(voxel_tensors.shape[0]*0.8)\n",
    "data = voxel_tensors[:num_data]\n",
    "holdout_data = voxel_tensors[num_data:]\n",
    "\n",
    "# Split into training and validation sets\n",
    "num_train_samples = int(data.shape[0]*0.8)\n",
    "train_data = data[:num_train_samples]\n",
    "val_data = data[num_train_samples:]\n",
    "\n",
    "# Define autoencoder parameters\n",
    "num_epochs = 100\n",
    "batch_size = 16\n",
    "\n",
    "# Train the autoencoder\n",
    "trained_autoencoder = train_autoencoder(train_data, val_data, num_epochs, batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 1000])\n",
      "torch.Size([6, 2, 40, 40, 40])\n"
     ]
    }
   ],
   "source": [
    "encoded_voxel = encode_voxel_grids(trained_autoencoder, holdout_data)\n",
    "\n",
    "print(encoded_voxel.shape)\n",
    "decoded_voxel = decode_voxel_grids(trained_autoencoder, encoded_voxel)\n",
    "print(decoded_voxel.shape)\n",
    "\n",
    "holdout_grids = split_combined_voxel_grids(holdout_data.cpu().data.numpy())\n",
    "decoded_grids = split_combined_voxel_grids(decoded_voxel.cpu().data.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27\n",
      "(2, 40, 40, 40)\n",
      "(40, 40, 40)\n"
     ]
    }
   ],
   "source": [
    "print(len(voxel_grids))\n",
    "print(voxel_grids[0].shape)\n",
    "\n",
    "test_grids = split_combined_voxel_grids(voxel_grids)\n",
    "\n",
    "print(test_grids[0].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_pcd(grid):\n",
    "    voxel_size = 0.0075\n",
    "    threshold = 0.1\n",
    "    points = np.argwhere(grid > threshold) #* voxel_size\n",
    "    distances = np.expand_dims(grid[grid > threshold], 1)\n",
    "    pcd = o3d.geometry.PointCloud()\n",
    "    pcd.points = o3d.utility.Vector3dVector(points)\n",
    "\n",
    "    return pcd\n",
    "\n",
    "active = True\n",
    "\n",
    "def kill_o3d(sender):\n",
    "    global active\n",
    "    active = False\n",
    "\n",
    "tsdf_exists = False\n",
    "reset_bb = False\n",
    "\n",
    "o3d.core.Device(\"cuda:0\")\n",
    "\n",
    "vis = o3d.visualization.VisualizerWithKeyCallback()\n",
    "\n",
    "vis.register_key_callback(ord(\"X\"), kill_o3d)\n",
    "\n",
    "vis.create_window(window_name = \"Depth Camera\")\n",
    "\n",
    "pcd = o3d.io.read_point_cloud(file_paths[0])\n",
    "\n",
    "test_pcd = to_pcd(test_grids[0])\n",
    "\n",
    "holdout_pc_grid = holdout_grids[2]\n",
    "\n",
    "decoded_pc_grid = decoded_grids[2]\n",
    "\n",
    "\n",
    "holdout_pcd = to_pcd(holdout_pc_grid)\n",
    "decode_pcd = to_pcd(decoded_pc_grid)\n",
    "decode_pcd.translate(np.asarray([0,-41,0]))\n",
    "\n",
    "frame = o3d.geometry.TriangleMesh.create_coordinate_frame(0.05)\n",
    "\n",
    "vis.add_geometry(holdout_pcd, reset_bounding_box = True)\n",
    "vis.add_geometry(decode_pcd, reset_bounding_box = True)\n",
    "vis.add_geometry(frame, reset_bounding_box = reset_bb)\n",
    "vis.update_renderer()\n",
    "\n",
    "while active:\n",
    "\n",
    "    vis.poll_events()\n",
    "    vis.update_renderer()\n",
    "\n",
    "vis.destroy_window()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
